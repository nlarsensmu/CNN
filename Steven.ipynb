{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "advanced-princess",
   "metadata": {},
   "source": [
    "# CNN with Brain Cell Images\n",
    "\n",
    "Nicholas Larsen\n",
    "Steven Larsen\n",
    "\n",
    "This data came from real world microscopic images.  Each image is a blood smear from a patient that was then placed on a slide for imaging.  This data was collected with the intention of classifing Acute Lymphoblastic Leukemia (ALL).  This can be a difficult task in, due to the differences between healthy and cells with leukemia being extremely small.  Each image from the data set was analyzed by an expert oncologist.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-tribe",
   "metadata": {},
   "source": [
    "# Load images, show a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e299b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import daisy\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from skimage.io import imshow\n",
    "from ipywidgets import widgets  # make this interactive!\n",
    "from ipywidgets import fixed\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "color-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_sacle(data):\n",
    "    return np.dot(data[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "def read_images(directories, grey_scale=False, verb = False):\n",
    "    \"\"\"Reads in the all and rem directoires under each directory in the list directories\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for direct in dirs:\n",
    "        if verb:\n",
    "            print(f\"Reading {direct}\")\n",
    "        direct_all = f\"{direct}\\\\all\"\n",
    "        for file in listdir(direct_all):\n",
    "            if verb:\n",
    "                print(f\"Reading file: {file}\")\n",
    "            image = Image.open(f\"{direct_all}\\\\{file}\")\n",
    "            data = np.asarray(image)\n",
    "            if grey_scale:\n",
    "                data = gray_sacle(data)\n",
    "            #data = data.ravel()\n",
    "            X.append(data)\n",
    "            y.append(1)\n",
    "                \n",
    "        direct_rem = f\"{direct}\\\\hem\"\n",
    "        for file in listdir(direct_rem):\n",
    "            if verb:\n",
    "                print(f\"Reading file: {file}\")\n",
    "            image = Image.open(f\"{direct_rem}\\\\{file}\")\n",
    "            data = np.asarray(image)\n",
    "            if grey_scale:\n",
    "                data = gray_sacle(data)\n",
    "            #data = data.ravel()\n",
    "            X.append(data)\n",
    "            y.append(0)\n",
    "                \n",
    "    return np.asarray(X), np.asarray(y)\n",
    "\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=6):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.7 * n_col, 2.3 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "recreational-commons",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(522, 450, 450, 3)\n",
      "Wall time: 9.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dirs = [\n",
    "#    r'..\\archive\\C-NMC_Leukemia\\training_data\\fold_0',\n",
    "#    r'..\\archive\\C-NMC_Leukemia\\training_data\\fold_1',\n",
    "#    r'..\\archive\\C-NMC_Leukemia\\training_data\\fold_2'\n",
    "    r'..\\archive\\C-NMC_Leukemia\\training_data\\fold_small'\n",
    "]\n",
    "X, y = read_images(dirs, verb=False)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-ancient",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e0bf9",
   "metadata": {},
   "source": [
    "## Explain Metrics\n",
    "\n",
    "We are very interested int the recall score.  Simply put this is because our data is operating in the medical field.  Our algorithm giving the OK to a patient that does have the disease we are trying to predict would be a very bad outcome.  We are still interested in the accuracy in general, since our algorithm will likely be used supplementary to an expert's opinion.  If our recall score is high enough we will be able to reduce the number of images doctors will have to sift through."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc18c2d",
   "metadata": {},
   "source": [
    "## Define splitting Techniques (why is this realistic in practice)\n",
    "\n",
    "Our data is going to be split into training and testing (80 / 20).  On the 80 we will perform stratified K folds.  This will just be used to compare the different models produced in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fd1c892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 450, 450, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the data\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9b6bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mlp = X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2]*X_train.shape[3])\n",
    "X_train_mlp.shape\n",
    "X_test_mlp = X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2]*X_test.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "001e156d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation recall: 0.2962962962962963\n",
      "Validation Acc: 0.7428571428571429\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Standard MLP for comparison\n",
    "#from sklearn import veresion as sklearn_version\n",
    "\n",
    "#print(sklearn_version)\n",
    "# these values have been hand tuned\n",
    "def MLP_create():\n",
    "    \n",
    "    \n",
    "    clf = MLPClassifier(hidden_layer_sizes=(50, 25, 12), \n",
    "                        activation='relu', # compare to sigmoid\n",
    "                        solver='adam', \n",
    "                        alpha=1e-4, # L2 penalty\n",
    "                        batch_size=128, # min of 200, num_samples\n",
    "                        learning_rate='adaptive', # decrease rate if loss goes up\n",
    "                        #learning_rate_init=0.1, # only SGD\n",
    "                        #power_t=0.5,    # only SGD with inverse scaling\n",
    "                        max_iter=20, \n",
    "                        shuffle=True, \n",
    "                        random_state=1, \n",
    "                        tol=1e-9, # for stopping\n",
    "                        verbose=False, \n",
    "                        warm_start=False, \n",
    "                        #momentum=0.9, # only SGD\n",
    "                        #nesterovs_momentum=True, # only SGD\n",
    "                        early_stopping=False, \n",
    "                        validation_fraction=0.1, # only if early_stop is true\n",
    "                        beta_1=0.9, # adam decay rate of moment\n",
    "                        beta_2=0.999, # adam decay rate of moment\n",
    "                        epsilon=1e-08) # adam numerical stabilizer\n",
    "    return clf\n",
    "clf = MLP_create()\n",
    "clf.fit(X_train_mlp,y_train)\n",
    "yhat = clf.predict(X_test_mlp)\n",
    "print('Validation recall:',recall_score(yhat,y_test))\n",
    "print('Validation Acc:',accuracy_score(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ae5c4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/2...\n",
      "Last training score:  0.4878048780487805\n",
      "Training on fold 2/2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last training score:  0.3953488372093023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4878048780487805, 0.3953488372093023]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://medium.com/@literallywords/stratified-k-fold-with-keras-e57c487b1416\n",
    "def stratifiedKFoldRuns(K=2, scorer=recall_score,model_create=MLP_create):\n",
    "    cv = StratifiedKFold(n_splits=K, shuffle=True)\n",
    "    my_scorer = make_scorer(scorer)\n",
    "\n",
    "    scores = [] \n",
    "    for index, (train_indices, val_indices) in enumerate(cv.split(X_train, y_train)):\n",
    "        print(f\"Training on fold {index+1}/{K}...\")\n",
    "\n",
    "        _X_train = X_train_mlp[train_indices]\n",
    "        _X_test = X_train_mlp[val_indices]\n",
    "        _y_train = y_train[train_indices]\n",
    "        _y_test = y_train[val_indices]\n",
    "        \n",
    "        \n",
    "        \n",
    "        model = model_create()\n",
    "        model.fit(_X_train,_y_train)\n",
    "        yhat = clf.predict(_X_test)\n",
    "        score = scorer(yhat,_y_test)\n",
    "    \n",
    "        scores.append(score)\n",
    "        print(\"Last training score: \",score)\n",
    "    return scores\n",
    "stratifiedKFoldRuns()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-strain",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-sacramento",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-tuner",
   "metadata": {},
   "source": [
    "## Set up Data Expansion in Keras. \n",
    "### Options from town hall\n",
    "* Data augmentation he showed an example of. Tends to be slow\n",
    "* Go through and a couple of passes of expansion'\n",
    "* Use expansion for a couple of epic at the end\n",
    "### Reasoning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-running",
   "metadata": {},
   "source": [
    "## Create Convolutional Neural Network using Keras. \n",
    "* Investigate different parameters on at least two different network architectures\n",
    "* Architectural Differences\n",
    " * Number of layers\n",
    " * Whether or not using residual paths\n",
    " * Seperable convolutions\n",
    " \n",
    "Need a total of 4 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "muslim-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-summer",
   "metadata": {},
   "source": [
    "## Visualize the final Results\n",
    "* Visualize\n",
    "* Compare statistically\n",
    "* Compare the performance to a standard ML_P using the receiver operating characteristic and the area under the curve\n",
    "This includes:\n",
    "* Which one is the best\n",
    "* Which one you should choose\n",
    "* How might you deploy it\n",
    "* All of the things you might be interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "choice-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-discharge",
   "metadata": {},
   "source": [
    "# Use transfer learning to pre-train weights of your initial layers of CNN\n",
    "* Compare to best other model\n",
    "* There is an exmaple in his notebook. Use Img Net weights, VGG. Compare from scratch from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
